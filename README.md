

# Retrieval-Augmented Robustness â€” Experiments with RaCNN, ViT & Mixup Variants

This repository explores **Retrieval-Augmented Convolutional Networks (RaCNN)** and their modern variants to study adversarial robustness and manifold regularization techniques.

---

## ğŸ“Project Overview

| Experiment | Description |
|-------------|-------------|
| `ra-cnn-resnet` | Replication of Cho et al. (NeurIPS 2019) using ResNet-18 backbone and FAISS retrieval engine. |
| `ra-cnn-vit` | RaCNN modified with a Vision Transformer (ViT) backbone instead of CNN. |
| `ra-cnn-automixup` | Incorporates AutoMixup (AAAI 2021) as an alternative to the local mixup used in RaCNN. |

---

## ğŸ§  Background

The RaCNN architecture combines:
- A **retrieval engine (Ï†â€²)** to construct a local convex hull of neighbors,
- A **projection module** using attention weights to map inputs back onto the data manifold,
- And **local mixup regularization** to improve linearity within the manifold.

This approach addresses **both on-manifold and off-manifold adversarial attacks**.

---

## âš™ï¸ Setup

```bash
pip install torch torchvision faiss-cpu torchattacks tqdm matplotlib
````

---

## ğŸ“ Folder Structure

```
notebooks/
  ra-cnn-resnet/     â†’ paper replication (ResNet backbone)
  ra-cnn-vit/        â†’ transformer backbone variant
  ra-cnn-automixup/  â†’ alternative mixup function
src/                 â†’ reusable modules (retrieval, backbones, projection, etc.)
docs/                â†’ experiment logs & diagrams
```

---


---

## ğŸ“š References

* Cho et al., *Retrieval-Augmented Convolutional Neural Networks against Adversarial Examples*, NeurIPS 2019.
* Dosovitskiy et al., *An Image is Worth 16Ã—16 Words: Transformers for Image Recognition at Scale*, ICLR 2021.
* Qin et al., *Adversarial AutoMixup*, ICLR 2024.


````