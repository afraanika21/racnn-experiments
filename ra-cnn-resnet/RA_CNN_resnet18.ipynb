{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G5Eh1Dxe2PR",
        "outputId": "99a5b7b2-c5b3-450f-e907-2ee51de5ef6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n",
            "Collecting torchattacks\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (0.23.0+cu126)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (1.16.2)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (4.67.1)\n",
            "Collecting requests~=2.25.1 (from torchattacks)\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.0.2)\n",
            "Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.8.2->torchattacks) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.1->torchattacks) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (3.0.3)\n",
            "Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, idna, chardet, requests, torchattacks\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.25.1 which is incompatible.\n",
            "tiktoken 0.12.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\n",
            "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.25.1 which is incompatible.\n",
            "google-genai 1.45.0 requires requests<3.0.0,>=2.28.1, but you have requests 2.25.1 which is incompatible.\n",
            "yfinance 0.2.66 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\n",
            "libpysal 4.13.0 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\n",
            "google-adk 1.16.0 requires requests<3.0.0,>=2.32.4, but you have requests 2.25.1 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\n",
            "bigframes 2.25.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n",
            "tweepy 4.16.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 requests-2.25.1 torchattacks-3.5.1 urllib3-1.26.20\n"
          ]
        }
      ],
      "source": [
        "# Colab cell 1: install dependencies\n",
        "# - faiss-cpu for fast nearest-neighbor search (IndexFlatL2)\n",
        "# - torchattacks optional (we also include minimal FGSM/PGD implementations)\n",
        "# Note: use faiss-gpu if available, but faiss-cpu works fine for CIFAR-10.\n",
        "!pip install faiss-cpu\n",
        "!pip install torchattacks\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2\n",
        "# Standard imports and hyperparameters. Change these to suit your GPU/time budget.\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import faiss  # for retrieval index\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device (Colab T4)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Reproducibility seeds\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Hyperparameters (start values tuned for Colab)\n",
        "IMG_SIZE = 224            # using ResNet-18 pretrained requires 224x224\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2\n",
        "NUM_CLASSES = 10          # CIFAR-10\n",
        "LR = 1e-3\n",
        "EPOCHS = 20               # lower for quick runs; increase if you have time\n",
        "K = 10                     # default retrieved neighbors\n",
        "K_OPTIONS = [5, 10]       # experiment with 5 and 10 as in paper\n",
        "C = 10                    # K' = C*K for randomization if used\n",
        "MIXUP_WEIGHT = 0.5        # weight for local mixup loss in total loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYv2zbrdfJlK",
        "outputId": "67106703-1c80-41d5-b41f-a83d8721c0b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 3\n",
        "# Dataset pipeline: Resize to 224 for ResNet-18. (Paper used custom small network for CIFAR; ResNet-18 is fine.)\n",
        "transform_train = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225)),\n",
        "])\n",
        "transform_test = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader  = torch.utils.data.DataLoader(testset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "print(\"Train size:\", len(trainset), \"Test size:\", len(testset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdjOhLEAfY44",
        "outputId": "8263f7ff-00e9-442f-8d35-ca4ecf68c74f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 41.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 50000 Test size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 4\n",
        "# Implements Section 2 (phi' and phi). phi_prime can be pretrained ResNet-18 (frozen) used for retrieval keys.\n",
        "# phi is the trainable feature extractor used inside RaCNN. For simplicity we use same architecture for both.\n",
        "\n",
        "def get_resnet18_backbone(pretrained=True, out_dim=None):\n",
        "    \"\"\"\n",
        "    Returns ResNet18 truncated before final fc.\n",
        "    If out_dim given, add a linear layer to project to out_dim.\n",
        "    \"\"\"\n",
        "    model = torchvision.models.resnet18(pretrained=pretrained)\n",
        "    modules = list(model.children())[:-1]  # remove fc\n",
        "    encoder = nn.Sequential(*modules)      # outputs [B, 512, 1, 1]\n",
        "    class Wrapper(nn.Module):\n",
        "        def __init__(self, encoder, out_dim=None):\n",
        "            super().__init__()\n",
        "            self.encoder = encoder\n",
        "            self.out_dim = out_dim\n",
        "            self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "            if out_dim is not None:\n",
        "                self.proj = nn.Linear(512, out_dim)\n",
        "            else:\n",
        "                self.proj = None\n",
        "        def forward(self, x):\n",
        "            h = self.encoder(x)\n",
        "            h = h.view(h.size(0), -1)\n",
        "            if self.proj is not None:\n",
        "                return self.proj(h)\n",
        "            return h\n",
        "    return Wrapper(encoder, out_dim=out_dim)\n",
        "\n",
        "# instantiate\n",
        "# phi_prime: the retrieval key extractor (Section 2.3). We will freeze it by default (simulate hidden retrieval).\n",
        "phi_prime = get_resnet18_backbone(pretrained=True, out_dim=None).to(device)\n",
        "for p in phi_prime.parameters():\n",
        "    p.requires_grad = False  # freeze phi' by default\n",
        "\n",
        "# phi: trainable feature extractor used by RaCNN (can start from pretrained backbone or random init)\n",
        "phi = get_resnet18_backbone(pretrained=True, out_dim=None).to(device)\n",
        "# Option: fine-tune or freeze early layers as you prefer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxocxq7rgI4a",
        "outputId": "1a8bcc64-7d88-4cc0-8e3a-d719151bd14d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 194MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# 📘 Dataset Preparation — CIFAR-10 (Section 6.1)\n",
        "# ==============================================================\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Data augmentation (same spirit as Sec. 6: \"data augmentation on D but not D′\")\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train\n",
        ")\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test\n",
        ")\n",
        "\n",
        "# Dataloaders (as D and D′)\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"[RaCNN] CIFAR-10 ready — {len(trainset)} train, {len(testset)} test samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZmD6078iz9t",
        "outputId": "0e933388-ffb8-49ee-e1af-4773c98ce5d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RaCNN] CIFAR-10 ready — 50000 train, 10000 test samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# 📘 Section 2.3 — Retrieval Engine F\n",
        "# ==============================================================\n",
        "# This builds the retrieval database D′ = {φ′(x′i), y′i}.\n",
        "# In the paper: they use LSH + random projection.\n",
        "# Here: we use FAISS IndexFlatL2 (dense lookup, faster & GPU compatible).\n",
        "# Optional random projection (dim reduction) can be added with out_dim in phi′.\n",
        "\n",
        "import os, faiss, numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "SAVE_DIR = '/content/drive/MyDrive/racnn'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "DB_FEATS_PATH = os.path.join(SAVE_DIR, 'db_feats.npy')\n",
        "DB_LABELS_PATH = os.path.join(SAVE_DIR, 'db_labels.npy')\n",
        "DB_INDEX_PATH = os.path.join(SAVE_DIR, 'retrieval_index.faiss')\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 🔹 Helper: build retrieval DB if not cached\n",
        "# --------------------------------------------------------------\n",
        "def build_feature_db(dataloader, feature_extractor):\n",
        "    feature_extractor.eval()\n",
        "    feats, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in tqdm(dataloader, desc=\"[RaCNN] Building retrieval DB\"):\n",
        "            imgs = imgs.to(device)\n",
        "            f = feature_extractor(imgs).cpu().numpy()\n",
        "            feats.append(f)\n",
        "            labels.append(lbls.numpy())\n",
        "    feats = np.concatenate(feats, axis=0)\n",
        "    labels = np.concatenate(labels, axis=0)\n",
        "    return feats, labels\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 🔹 Step 1: Try to load saved retrieval DB\n",
        "# --------------------------------------------------------------\n",
        "if all(os.path.exists(p) for p in [DB_FEATS_PATH, DB_LABELS_PATH, DB_INDEX_PATH]):\n",
        "    print(\"[RaCNN] Loading cached retrieval database from Drive...\")\n",
        "    db_feats = np.load(DB_FEATS_PATH)\n",
        "    db_labels = np.load(DB_LABELS_PATH)\n",
        "    index = faiss.read_index(DB_INDEX_PATH)\n",
        "\n",
        "else:\n",
        "    print(\"[RaCNN] Building retrieval database from scratch (first run)...\")\n",
        "    db_feats, db_labels = build_feature_db(trainloader, phi_prime)\n",
        "\n",
        "    # FAISS index construction (equiv. to 'retrieval engine F' in Sec. 2.3)\n",
        "    d = db_feats.shape[1]\n",
        "    index = faiss.IndexFlatL2(d)\n",
        "    index.add(db_feats)\n",
        "\n",
        "    # Save to Drive (so we can skip this next time)\n",
        "    np.save(DB_FEATS_PATH, db_feats)\n",
        "    np.save(DB_LABELS_PATH, db_labels)\n",
        "    faiss.write_index(index, DB_INDEX_PATH)\n",
        "    print(f\"[RaCNN] Saved retrieval DB to {SAVE_DIR}\")\n",
        "\n",
        "print(f\"[RaCNN] Retrieval DB ready — {len(db_labels)} examples indexed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr8UjjrMibDu",
        "outputId": "35cd5788-b7eb-4672-c207-3d64a840f593"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RaCNN] Building retrieval database from scratch (first run)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[RaCNN] Building retrieval DB: 100%|██████████| 391/391 [00:20<00:00, 19.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RaCNN] Saved retrieval DB to /content/drive/MyDrive/racnn\n",
            "[RaCNN] Retrieval DB ready — 50000 examples indexed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# 📘 Section 2.1 — Trainable Projection via Attention (βₖ, αₖ, P(x))\n",
        "# ==============================================================\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TrainableProjection(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements Eqns. (βₖ, αₖ, P(x)) from Section 2.1:\n",
        "      βₖ = φ(x′ₖ)^T U φ(x)\n",
        "      αₖ = softmax(βₖ)\n",
        "      P(x) = Σ αₖ φ(x′ₖ)\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_dim):\n",
        "        super().__init__()\n",
        "        self.U = nn.Parameter(torch.eye(feature_dim))  # trainable weight matrix U\n",
        "\n",
        "    def forward(self, phi_x, phi_neighbors):\n",
        "        \"\"\"\n",
        "        phi_x:         [B, D] — feature of input image φ(x)\n",
        "        phi_neighbors: [B, K, D] — features of K retrieved neighbors φ(x′ₖ)\n",
        "        returns:\n",
        "            P(x): projected feature [B, D]\n",
        "            α: attention weights [B, K]\n",
        "        \"\"\"\n",
        "        # Compute βₖ = φ(x′ₖ)^T U φ(x)\n",
        "        B, K, D = phi_neighbors.shape\n",
        "        Uphi = F.linear(phi_x, self.U)  # [B, D]\n",
        "        beta = torch.bmm(phi_neighbors, Uphi.unsqueeze(2)).squeeze(2)  # [B, K]\n",
        "\n",
        "        # αₖ = softmax(βₖ)\n",
        "        alpha = F.softmax(beta, dim=1)  # [B, K]\n",
        "\n",
        "        # Weighted sum: P(x) = Σ αₖ φ(x′ₖ)\n",
        "        P = torch.bmm(alpha.unsqueeze(1), phi_neighbors).squeeze(1)  # [B, D]\n",
        "        return P, alpha\n"
      ],
      "metadata": {
        "id": "oVr5lKx_jvtm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# 📘 Section 2.2 — Training with Local Mixup + Classifier g\n",
        "# ==============================================================\n",
        "\n",
        "class ClassifierHead(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements g from Section 2.\n",
        "    In the paper, g is the final classifier after the projection P(x).\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_dim=512, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(feature_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 🔹 Local Mixup implementation\n",
        "# --------------------------------------------------------------\n",
        "def local_mixup(phi_neighbors, y_neighbors):\n",
        "    \"\"\"\n",
        "    Implements Eqn. for Local Mixup (Section 2.2):\n",
        "      (Σ αₖ φ(x′ₖ), Σ αₖ y′ₖ)\n",
        "    α sampled uniformly on the simplex (Kraemer Algorithm).\n",
        "    \"\"\"\n",
        "    B, K, D = phi_neighbors.shape\n",
        "    device = phi_neighbors.device\n",
        "    # sample convex coefficients αₖ ≥ 0, Σ αₖ = 1\n",
        "    rand = torch.rand(B, K, device=device)\n",
        "    alpha = rand / rand.sum(dim=1, keepdim=True)\n",
        "    # new mixed feature and label\n",
        "    mixed_feat = torch.bmm(alpha.unsqueeze(1), phi_neighbors).squeeze(1)   # [B, D]\n",
        "    mixed_label = torch.bmm(alpha.unsqueeze(1), y_neighbors).squeeze(1)   # [B, num_classes]\n",
        "    return mixed_feat, mixed_label\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 🔹 Full RaCNN Model: φ, F(x), Projection (U), Classifier (g)\n",
        "# --------------------------------------------------------------\n",
        "class RaCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Combines all modules from Section 2:\n",
        "      - Feature extractor φ\n",
        "      - Trainable projection (U, αₖ, convex hull)\n",
        "      - Classifier g\n",
        "    Retrieval F(x) and φ′ handled externally (FAISS + precomputed db_feats)\n",
        "    \"\"\"\n",
        "    def __init__(self, phi, projection, classifier, index, db_feats, db_labels, K=10):\n",
        "        super().__init__()\n",
        "        self.phi = phi\n",
        "        self.projection = projection\n",
        "        self.classifier = classifier\n",
        "        self.index = index\n",
        "        self.db_feats = db_feats\n",
        "        self.db_labels = db_labels\n",
        "        self.K = K\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass:\n",
        "          1. extract φ(x)\n",
        "          2. retrieve K nearest neighbors via FAISS (F(x))\n",
        "          3. project x onto convex hull (Eqn. 2.1)\n",
        "          4. classify g(P(x))\n",
        "        \"\"\"\n",
        "        # Step 1: feature for input x\n",
        "        phi_x = self.phi(x)                       # [B, D]\n",
        "        phi_x_np = phi_x.detach().cpu().numpy()\n",
        "\n",
        "        # Step 2: retrieve neighbors in φ′ space (F(x))\n",
        "        D, I = self.index.search(phi_x_np, self.K)\n",
        "        phi_neighbors = torch.tensor(self.db_feats[I], dtype=torch.float32, device=x.device)\n",
        "        y_neighbors = torch.nn.functional.one_hot(\n",
        "            torch.tensor(self.db_labels[I], device=x.device), num_classes=10\n",
        "        ).float()\n",
        "\n",
        "        # Step 3: project x to convex hull (trainable projection)\n",
        "        P, alpha = self.projection(phi_x, phi_neighbors)\n",
        "\n",
        "        # Step 4: classify\n",
        "        logits = self.classifier(P)\n",
        "        return logits, P, alpha\n"
      ],
      "metadata": {
        "id": "1V4HKa6xkbWV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# 📘 Section 2.2 + Section 6 — Training Loop for RaCNN\n",
        "# ==============================================================\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# instantiate all components\n",
        "feature_dim = 512\n",
        "projection = TrainableProjection(feature_dim).to(device)\n",
        "classifier = ClassifierHead(feature_dim, num_classes=10).to(device)\n",
        "model = RaCNN(phi, projection, classifier, index, db_feats, db_labels, K=5).to(device)\n",
        "\n",
        "# optimizer (paper: \"we use stochastic gradient descent\")\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# loss criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# training hyperparams\n",
        "num_epochs = 20          # keep small in Colab\n",
        "NCE_steps = 1           # classification steps\n",
        "NMU_steps = 5           # local mixup steps\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss, running_mixup_loss = 0.0, 0.0\n",
        "    pbar = tqdm(trainloader, desc=f\"[Epoch {epoch+1}/{num_epochs}]\")\n",
        "    for imgs, labels in pbar:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        onehot = F.one_hot(labels, num_classes=10).float()\n",
        "\n",
        "        # ----------------------------------------------------------\n",
        "        # 1️⃣ Classification loss (NCE step)\n",
        "        # ----------------------------------------------------------\n",
        "        optimizer.zero_grad()\n",
        "        logits, P, _ = model(imgs)\n",
        "        loss_cls = criterion(logits, labels)\n",
        "        loss_cls.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss_cls.item()\n",
        "\n",
        "        # ----------------------------------------------------------\n",
        "        # 2️⃣ Local Mixup regularization (NMU step)\n",
        "        # ----------------------------------------------------------\n",
        "        with torch.no_grad():\n",
        "            # retrieve neighbors again for mixup\n",
        "            phi_x = model.phi(imgs)\n",
        "            phi_x_np = phi_x.detach().cpu().numpy()\n",
        "            _, I = model.index.search(phi_x_np, model.K)\n",
        "            phi_neighbors = torch.tensor(model.db_feats[I], dtype=torch.float32, device=device)\n",
        "            y_neighbors = F.one_hot(\n",
        "                torch.tensor(model.db_labels[I], device=device), num_classes=10\n",
        "            ).float()\n",
        "\n",
        "        mixed_feat, mixed_label = local_mixup(phi_neighbors, y_neighbors)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits_mix = model.classifier(mixed_feat)\n",
        "        loss_mix = F.cross_entropy(logits_mix, mixed_label.argmax(dim=1))\n",
        "        loss_mix.backward()\n",
        "        optimizer.step()\n",
        "        running_mixup_loss += loss_mix.item()\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            \"cls_loss\": f\"{running_loss/len(trainloader):.3f}\",\n",
        "            \"mix_loss\": f\"{running_mixup_loss/len(trainloader):.3f}\"\n",
        "        })\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Cls Loss {running_loss/len(trainloader):.4f} | Mix Loss {running_mixup_loss/len(trainloader):.4f}\")\n",
        "\n",
        "print(\"✅ Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9N-Y_T9ko95",
        "outputId": "2d76a9bf-a5f5-4cba-8115-725cc422e723"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 1/20]: 100%|██████████| 391/391 [02:11<00:00,  2.98it/s, cls_loss=1.765, mix_loss=1.331]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Cls Loss 1.7652 | Mix Loss 1.3310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 2/20]: 100%|██████████| 391/391 [02:11<00:00,  2.98it/s, cls_loss=1.657, mix_loss=1.123]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Cls Loss 1.6569 | Mix Loss 1.1229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 3/20]: 100%|██████████| 391/391 [02:12<00:00,  2.96it/s, cls_loss=1.573, mix_loss=1.042]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Cls Loss 1.5733 | Mix Loss 1.0415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 4/20]: 100%|██████████| 391/391 [02:10<00:00,  3.00it/s, cls_loss=1.527, mix_loss=1.025]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Cls Loss 1.5268 | Mix Loss 1.0248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 5/20]: 100%|██████████| 391/391 [02:11<00:00,  2.97it/s, cls_loss=1.479, mix_loss=0.975]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Cls Loss 1.4794 | Mix Loss 0.9754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 6/20]: 100%|██████████| 391/391 [02:12<00:00,  2.96it/s, cls_loss=1.450, mix_loss=1.036]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Cls Loss 1.4503 | Mix Loss 1.0362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 7/20]: 100%|██████████| 391/391 [02:10<00:00,  2.99it/s, cls_loss=1.415, mix_loss=1.012]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Cls Loss 1.4154 | Mix Loss 1.0117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 8/20]: 100%|██████████| 391/391 [02:11<00:00,  2.97it/s, cls_loss=1.393, mix_loss=0.982]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Cls Loss 1.3928 | Mix Loss 0.9815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 9/20]: 100%|██████████| 391/391 [02:11<00:00,  2.97it/s, cls_loss=1.376, mix_loss=0.964]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Cls Loss 1.3759 | Mix Loss 0.9642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 10/20]: 100%|██████████| 391/391 [02:13<00:00,  2.93it/s, cls_loss=1.314, mix_loss=0.978]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Cls Loss 1.3139 | Mix Loss 0.9782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 11/20]: 100%|██████████| 391/391 [02:11<00:00,  2.97it/s, cls_loss=1.274, mix_loss=0.936]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Cls Loss 1.2736 | Mix Loss 0.9361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 12/20]: 100%|██████████| 391/391 [02:11<00:00,  2.98it/s, cls_loss=1.232, mix_loss=0.905]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Cls Loss 1.2323 | Mix Loss 0.9050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 13/20]: 100%|██████████| 391/391 [02:07<00:00,  3.06it/s, cls_loss=1.204, mix_loss=0.848]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Cls Loss 1.2041 | Mix Loss 0.8485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 14/20]: 100%|██████████| 391/391 [02:10<00:00,  3.01it/s, cls_loss=1.224, mix_loss=0.848]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Cls Loss 1.2235 | Mix Loss 0.8475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 15/20]: 100%|██████████| 391/391 [02:09<00:00,  3.03it/s, cls_loss=1.164, mix_loss=0.813]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Cls Loss 1.1636 | Mix Loss 0.8129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 16/20]: 100%|██████████| 391/391 [02:10<00:00,  3.00it/s, cls_loss=1.132, mix_loss=0.787]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Cls Loss 1.1322 | Mix Loss 0.7870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 17/20]: 100%|██████████| 391/391 [02:09<00:00,  3.03it/s, cls_loss=1.239, mix_loss=0.816]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Cls Loss 1.2388 | Mix Loss 0.8159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 18/20]: 100%|██████████| 391/391 [02:10<00:00,  3.00it/s, cls_loss=1.127, mix_loss=0.761]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Cls Loss 1.1273 | Mix Loss 0.7613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 19/20]: 100%|██████████| 391/391 [02:11<00:00,  2.98it/s, cls_loss=1.063, mix_loss=0.739]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Cls Loss 1.0632 | Mix Loss 0.7388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 20/20]: 100%|██████████| 391/391 [02:10<00:00,  3.00it/s, cls_loss=1.037, mix_loss=0.744]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Cls Loss 1.0368 | Mix Loss 0.7444\n",
            "✅ Training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# 📘 Section 6 — Evaluation under Adversarial Attacks\n",
        "# ==============================================================\n",
        "\n",
        "def fgsm_attack(model, images, labels, eps=0.03):\n",
        "    \"\"\"Implements FGSM: x_adv = x + eps * sign(∇x L(x, y)).\"\"\"\n",
        "    images = images.clone().detach().to(device)\n",
        "    images.requires_grad = True\n",
        "\n",
        "    outputs, _, _ = model(images)\n",
        "    loss = F.cross_entropy(outputs, labels)\n",
        "    loss.backward()\n",
        "    adv_images = images + eps * images.grad.sign()\n",
        "    adv_images = torch.clamp(adv_images, -1, 1)   # keep normalized range\n",
        "    return adv_images.detach()\n",
        "\n",
        "def ifgsm_attack(model, images, labels, eps=0.03, alpha=0.005, iters=10):\n",
        "    \"\"\"Iterative FGSM (a.k.a. PGD-lite).\"\"\"\n",
        "    images = images.clone().detach().to(device)\n",
        "    adv_images = images.clone().detach()\n",
        "\n",
        "    for _ in range(iters):\n",
        "        adv_images.requires_grad = True\n",
        "        outputs, _, _ = model(adv_images)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        adv_images = adv_images + alpha * adv_images.grad.sign()\n",
        "        eta = torch.clamp(adv_images - images, min=-eps, max=eps)\n",
        "        adv_images = torch.clamp(images + eta, -1, 1).detach()\n",
        "    return adv_images\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 🔹 Evaluation function\n",
        "# --------------------------------------------------------------\n",
        "def evaluate(model, dataloader, attack=None):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for imgs, labels in tqdm(dataloader, desc=f\"[Eval {attack or 'Clean'}]\"):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        if attack == 'FGSM':\n",
        "            imgs = fgsm_attack(model, imgs, labels)\n",
        "        elif attack == 'iFGSM':\n",
        "            imgs = ifgsm_attack(model, imgs, labels)\n",
        "        with torch.no_grad():\n",
        "            outputs, _, _ = model(imgs)\n",
        "            preds = outputs.argmax(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 🔹 Evaluate RaCNN vs. Vanilla CNN\n",
        "# --------------------------------------------------------------\n",
        "print(\"\\n🧪 Evaluating robustness (CIFAR-10 test set)...\")\n",
        "\n",
        "# Baseline CNN (vanilla)\n",
        "vanilla = get_resnet18_backbone(pretrained=False)\n",
        "vanilla.fc = nn.Linear(512, 10)\n",
        "vanilla = vanilla.to(device)\n",
        "# assume it's randomly initialized — used to show difference in robustness\n",
        "\n",
        "acc_clean_racnn = evaluate(model, testloader, None)\n",
        "acc_fgsm_racnn  = evaluate(model, testloader, 'FGSM')\n",
        "acc_ifgsm_racnn = evaluate(model, testloader, 'iFGSM')\n",
        "\n",
        "print(f\"✅ RaCNN accuracy — Clean: {acc_clean_racnn:.2f}% | FGSM: {acc_fgsm_racnn:.2f}% | iFGSM: {acc_ifgsm_racnn:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95rNDaEBnf_V",
        "outputId": "02851501-2a5d-4980-c997-3d831920eccb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧪 Evaluating robustness (CIFAR-10 test set)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Eval Clean]: 100%|██████████| 79/79 [00:11<00:00,  7.15it/s]\n",
            "[Eval FGSM]: 100%|██████████| 79/79 [00:25<00:00,  3.13it/s]\n",
            "[Eval iFGSM]: 100%|██████████| 79/79 [02:09<00:00,  1.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ RaCNN accuracy — Clean: 69.02% | FGSM: 29.82% | iFGSM: 20.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# 📘 Extended Adversarial Evaluation — Full Suite (Section 6)\n",
        "# ==============================================================\n",
        "import torchattacks\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 🔹 Fix for torchattacks — wrapper that only returns logits\n",
        "# --------------------------------------------------------------\n",
        "class LogitsWrapper(nn.Module):\n",
        "    def __init__(self, racnn):\n",
        "        super().__init__()\n",
        "        self.racnn = racnn\n",
        "    def forward(self, x):\n",
        "        logits, _, _ = self.racnn(x)\n",
        "        return logits\n",
        "\n",
        "# use wrapper for attacks (torchattacks expects logits only)\n",
        "wrapped_model = LogitsWrapper(model)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 🔹 Define attacks (matches Section 6 of the paper)\n",
        "# --------------------------------------------------------------\n",
        "atk_fgsm     = torchattacks.FGSM(wrapped_model, eps=0.03)\n",
        "atk_ifgsm    = torchattacks.PGD(wrapped_model, eps=0.03, alpha=0.005, steps=10)   # ≈ iFGSM\n",
        "atk_pgd      = torchattacks.PGD(wrapped_model, eps=0.03, alpha=0.005, steps=20)   # stronger PGD\n",
        "atk_deepfool = torchattacks.DeepFool(wrapped_model, steps=50)\n",
        "atk_cw       = torchattacks.CW(wrapped_model, c=1, kappa=0, steps=50, lr=0.01)\n",
        "atk_noise    = lambda x, y: torch.clamp(x + 0.03 * torch.randn_like(x), -1, 1)  # random Gaussian noise\n",
        "\n",
        "# Wrap all attacks in a dict\n",
        "attacks = {\n",
        "    \"Clean\":    None,\n",
        "    \"FGSM\":     atk_fgsm,\n",
        "    \"iFGSM\":    atk_ifgsm,\n",
        "    \"PGD\":      atk_pgd,\n",
        "    \"DeepFool\": atk_deepfool,\n",
        "    \"CW\":       atk_cw,\n",
        "    \"Noise\":    atk_noise,\n",
        "}\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 🔹 Evaluation loop\n",
        "# --------------------------------------------------------------\n",
        "def evaluate_adv(model, dataloader, attacks):\n",
        "    \"\"\"Evaluate model under multiple attacks.\"\"\"\n",
        "    model.eval()\n",
        "    results = {}\n",
        "    for name, atk in attacks.items():\n",
        "        correct, total = 0, 0\n",
        "        for imgs, labels in tqdm(dataloader, desc=f\"[Eval {name}]\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            if atk is not None:\n",
        "                if callable(atk):  # noise\n",
        "                    imgs = atk(imgs, labels)\n",
        "                else:\n",
        "                    imgs = atk(imgs, labels)\n",
        "            with torch.no_grad():\n",
        "                outputs, _, _ = model(imgs)\n",
        "                preds = outputs.argmax(1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "        acc = 100 * correct / total\n",
        "        results[name] = acc\n",
        "        print(f\"{name:10s}: {acc:.2f}%\")\n",
        "    return results\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 🚀 Run full evaluation\n",
        "# --------------------------------------------------------------\n",
        "print(\"🧪 Evaluating RaCNN robustness under full attack suite (CIFAR-10)...\")\n",
        "results = evaluate_adv(model, testloader, attacks)\n",
        "\n",
        "print(\"\\n✅ RaCNN Robustness Summary:\")\n",
        "for k, v in results.items():\n",
        "    print(f\"{k:10s}: {v:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6XYKpRx8YrD",
        "outputId": "c5c35429-a12c-43a4-f302-a42dfc5ec8a2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 Evaluating RaCNN robustness under full attack suite (CIFAR-10)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Eval Clean]: 100%|██████████| 79/79 [00:10<00:00,  7.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean     : 69.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Eval FGSM]: 100%|██████████| 79/79 [00:24<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM      : 38.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Eval iFGSM]: 100%|██████████| 79/79 [02:11<00:00,  1.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iFGSM     : 15.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Eval PGD]: 100%|██████████| 79/79 [04:07<00:00,  3.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD       : 13.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Eval DeepFool]: 100%|██████████| 79/79 [50:38<00:00, 38.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepFool  : 10.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Eval CW]: 100%|██████████| 79/79 [09:48<00:00,  7.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CW        : 10.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Eval Noise]: 100%|██████████| 79/79 [00:10<00:00,  7.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noise     : 65.77%\n",
            "\n",
            "✅ RaCNN Robustness Summary:\n",
            "Clean     : 69.02%\n",
            "FGSM      : 38.89%\n",
            "iFGSM     : 15.88%\n",
            "PGD       : 13.37%\n",
            "DeepFool  : 10.00%\n",
            "CW        : 10.00%\n",
            "Noise     : 65.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}